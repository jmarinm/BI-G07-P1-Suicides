{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a_aEDqao2Pzr"
   },
   "source": [
    "# 1. Importación y carga de Datos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "inrdBRZYiwLP"
   },
   "outputs": [],
   "source": [
    "#Importación de librerias\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn import model_selection, naive_bayes, svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import inflect\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, ClassifierMixin\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Importar/ Exportar modelos\n",
    "from joblib import dump, load\n",
    "\n",
    "#NLP\n",
    "\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize, RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TzE0OMpT8C2Q",
    "outputId": "22e95ac6-cafc-46ad-e932-9ef04fc41c4f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting inflect\n",
      "  Downloading inflect-6.0.2-py3-none-any.whl (34 kB)\n",
      "Collecting pydantic>=1.9.1\n",
      "  Downloading pydantic-1.10.2-cp37-cp37m-win_amd64.whl (2.1 MB)\n",
      "     ---------------------------------------- 2.1/2.1 MB 1.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pydantic>=1.9.1->inflect) (4.3.0)\n",
      "Installing collected packages: pydantic, inflect\n",
      "Successfully installed inflect-6.0.2 pydantic-1.10.2\n"
     ]
    }
   ],
   "source": [
    "!pip install inflect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WWWqZEOhTQvS",
    "outputId": "6d420b95-64e8-4295-ec5f-a06f5956d4e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Downloading nltk-3.7-py3-none-any.whl (1.5 MB)\n",
      "     ---------------------------------------- 1.5/1.5 MB 5.6 MB/s eta 0:00:00\n",
      "Collecting regex>=2021.8.3\n",
      "  Downloading regex-2022.10.31-cp37-cp37m-win_amd64.whl (268 kB)\n",
      "     -------------------------------------- 268.0/268.0 kB 5.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: click in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: joblib in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk) (4.64.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\kevin\\appdata\\roaming\\python\\python37\\site-packages (from click->nltk) (0.4.3)\n",
      "Requirement already satisfied: importlib-metadata in c:\\programdata\\anaconda3\\lib\\site-packages (from click->nltk) (4.11.3)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from importlib-metadata->click->nltk) (3.8.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from importlib-metadata->click->nltk) (4.3.0)\n",
      "Installing collected packages: regex, nltk\n",
      "Successfully installed nltk-3.7 regex-2022.10.31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\kevin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\kevin\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install nltk\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SJp3YhhIaYIJ",
    "outputId": "6d6443f6-cd0c-4bcc-8dcf-bf0b52e9ebf5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "rhcE2YTDLEtr"
   },
   "outputs": [],
   "source": [
    "np.random.seed(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "F3tIbXFK2diq"
   },
   "outputs": [],
   "source": [
    "#Carga de datos\n",
    "df_original=pd.read_csv('SuicidiosProyecto.csv', sep=',', encoding = 'utf-8', index_col=0)\n",
    "df_suicide = df_original.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "wnDS9cPI2_kc",
    "outputId": "77d83785-ec46-41d3-ca56-2b76a9cd529d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>173271</th>\n",
       "      <td>i want to destroy myselffor once everything wa...</td>\n",
       "      <td>suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336321</th>\n",
       "      <td>I kinda got behind schedule with learning for ...</td>\n",
       "      <td>non-suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256637</th>\n",
       "      <td>I'm just not sure anymoreFirst and foremost: I...</td>\n",
       "      <td>suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303772</th>\n",
       "      <td>please give me a reason to liveThats too much ...</td>\n",
       "      <td>suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293747</th>\n",
       "      <td>27f struggling to find meaning moving forwardI...</td>\n",
       "      <td>suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205651</th>\n",
       "      <td>Let’s get this bread 😎 Anyone know any good ba...</td>\n",
       "      <td>non-suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97174</th>\n",
       "      <td>Day 126 of posting random \"fun\" facts everyday...</td>\n",
       "      <td>non-suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195945</th>\n",
       "      <td>Little brother is self mutilating. Please help...</td>\n",
       "      <td>suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305273</th>\n",
       "      <td>Why do women always go in groups to their wash...</td>\n",
       "      <td>non-suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69929</th>\n",
       "      <td>Did you guys know that there's no school for g...</td>\n",
       "      <td>non-suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111327</th>\n",
       "      <td>Was about to post something... but forgot it w...</td>\n",
       "      <td>non-suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341361</th>\n",
       "      <td>Ah shite I said SUCK MY CLIT instead of SUCK M...</td>\n",
       "      <td>non-suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86906</th>\n",
       "      <td>if you hate coffee but need the caffeine try t...</td>\n",
       "      <td>non-suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281142</th>\n",
       "      <td>General Kenobi, Hello There First one to comme...</td>\n",
       "      <td>non-suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329342</th>\n",
       "      <td>Passively SuicidalI feel suicidal all the time...</td>\n",
       "      <td>suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197394</th>\n",
       "      <td>I wanna die but there’s so much I haven’t done...</td>\n",
       "      <td>suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31588</th>\n",
       "      <td>Trigger warning ⚠️ So I read a post on r/relat...</td>\n",
       "      <td>non-suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121402</th>\n",
       "      <td>I'm just tired and it's not worth itI feel lik...</td>\n",
       "      <td>suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67135</th>\n",
       "      <td>So I have covid and I'm stuck in my room for a...</td>\n",
       "      <td>non-suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33987</th>\n",
       "      <td>I hate my birthday. My life is looking darker ...</td>\n",
       "      <td>suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339803</th>\n",
       "      <td>I'm extremely close to suicide, and I could RE...</td>\n",
       "      <td>suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67240</th>\n",
       "      <td>I don't see a futureI've struggled for many ye...</td>\n",
       "      <td>suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141654</th>\n",
       "      <td>I cut myself and sent it too a group chatI am ...</td>\n",
       "      <td>suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124586</th>\n",
       "      <td>My ex is going out with me BOIS, but I have a ...</td>\n",
       "      <td>non-suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67736</th>\n",
       "      <td>Death grips ⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀</td>\n",
       "      <td>non-suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109589</th>\n",
       "      <td>But it hurts like hellHello.\\nI'd like to star...</td>\n",
       "      <td>suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228153</th>\n",
       "      <td>guys i am. too edgy fuck edginess it fucking s...</td>\n",
       "      <td>non-suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245384</th>\n",
       "      <td>A question for Americans What the fuck is goin...</td>\n",
       "      <td>non-suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255442</th>\n",
       "      <td>Does anyone not want to get better?I have good...</td>\n",
       "      <td>suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4015</th>\n",
       "      <td>Posts about how bad posts that say “unpopular ...</td>\n",
       "      <td>non-suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174069</th>\n",
       "      <td>Started watching X-Files and that shit 😩😩😩 X-F...</td>\n",
       "      <td>non-suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66167</th>\n",
       "      <td>Anyone need a video editor? I will edit videos...</td>\n",
       "      <td>non-suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12738</th>\n",
       "      <td>plague5467 appreciation post Please I need this</td>\n",
       "      <td>non-suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117336</th>\n",
       "      <td>u/MossIsUsuallyGreen appreciation post u are p...</td>\n",
       "      <td>non-suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322958</th>\n",
       "      <td>OH MY GOD IN ABOUT TO DIE JESUS CHRIST AT THE ...</td>\n",
       "      <td>non-suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74013</th>\n",
       "      <td>start a bruh chain ill go sleep now ​​​​​ ​​​​...</td>\n",
       "      <td>non-suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99974</th>\n",
       "      <td>Day 64 of posting lines from the Bee Movie eve...</td>\n",
       "      <td>non-suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219671</th>\n",
       "      <td>Shit I forgot to give reddit my email, and ive...</td>\n",
       "      <td>non-suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297484</th>\n",
       "      <td>I blew up at my abusive parents after they cal...</td>\n",
       "      <td>non-suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342310</th>\n",
       "      <td>I wish I had a girlfriend But I don’t have any...</td>\n",
       "      <td>non-suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273746</th>\n",
       "      <td>Every since my dad passed I want to join him.L...</td>\n",
       "      <td>suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74693</th>\n",
       "      <td>I feel stuckIdk if I want to feel better. Ther...</td>\n",
       "      <td>suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96111</th>\n",
       "      <td>short advice from a boy, about boys Boys are p...</td>\n",
       "      <td>non-suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181811</th>\n",
       "      <td>I have a question I can't upload images on r/t...</td>\n",
       "      <td>non-suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100617</th>\n",
       "      <td>Today Will Be My Last Day Alive!!Incoming Long...</td>\n",
       "      <td>suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286565</th>\n",
       "      <td>This is how people make me feel How I feel whe...</td>\n",
       "      <td>non-suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140727</th>\n",
       "      <td>Im lonely as heccc any quirky cuties wanna dm?...</td>\n",
       "      <td>non-suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328153</th>\n",
       "      <td>Try solve this numerical series 3; 5; 4; 9; 6;...</td>\n",
       "      <td>non-suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277381</th>\n",
       "      <td>Eternal Oblivion is Calling my Name. . .The la...</td>\n",
       "      <td>suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113347</th>\n",
       "      <td>Just kinda want to talk.I havent been in a gre...</td>\n",
       "      <td>suicide</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         text        class\n",
       "Unnamed: 0                                                                \n",
       "173271      i want to destroy myselffor once everything wa...      suicide\n",
       "336321      I kinda got behind schedule with learning for ...  non-suicide\n",
       "256637      I'm just not sure anymoreFirst and foremost: I...      suicide\n",
       "303772      please give me a reason to liveThats too much ...      suicide\n",
       "293747      27f struggling to find meaning moving forwardI...      suicide\n",
       "205651      Let’s get this bread 😎 Anyone know any good ba...  non-suicide\n",
       "97174       Day 126 of posting random \"fun\" facts everyday...  non-suicide\n",
       "195945      Little brother is self mutilating. Please help...      suicide\n",
       "305273      Why do women always go in groups to their wash...  non-suicide\n",
       "69929       Did you guys know that there's no school for g...  non-suicide\n",
       "111327      Was about to post something... but forgot it w...  non-suicide\n",
       "341361      Ah shite I said SUCK MY CLIT instead of SUCK M...  non-suicide\n",
       "86906       if you hate coffee but need the caffeine try t...  non-suicide\n",
       "281142      General Kenobi, Hello There First one to comme...  non-suicide\n",
       "329342      Passively SuicidalI feel suicidal all the time...      suicide\n",
       "197394      I wanna die but there’s so much I haven’t done...      suicide\n",
       "31588       Trigger warning ⚠️ So I read a post on r/relat...  non-suicide\n",
       "121402      I'm just tired and it's not worth itI feel lik...      suicide\n",
       "67135       So I have covid and I'm stuck in my room for a...  non-suicide\n",
       "33987       I hate my birthday. My life is looking darker ...      suicide\n",
       "339803      I'm extremely close to suicide, and I could RE...      suicide\n",
       "67240       I don't see a futureI've struggled for many ye...      suicide\n",
       "141654      I cut myself and sent it too a group chatI am ...      suicide\n",
       "124586      My ex is going out with me BOIS, but I have a ...  non-suicide\n",
       "67736            Death grips ⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀  non-suicide\n",
       "109589      But it hurts like hellHello.\\nI'd like to star...      suicide\n",
       "228153      guys i am. too edgy fuck edginess it fucking s...  non-suicide\n",
       "245384      A question for Americans What the fuck is goin...  non-suicide\n",
       "255442      Does anyone not want to get better?I have good...      suicide\n",
       "4015        Posts about how bad posts that say “unpopular ...  non-suicide\n",
       "174069      Started watching X-Files and that shit 😩😩😩 X-F...  non-suicide\n",
       "66167       Anyone need a video editor? I will edit videos...  non-suicide\n",
       "12738         plague5467 appreciation post Please I need this  non-suicide\n",
       "117336      u/MossIsUsuallyGreen appreciation post u are p...  non-suicide\n",
       "322958      OH MY GOD IN ABOUT TO DIE JESUS CHRIST AT THE ...  non-suicide\n",
       "74013       start a bruh chain ill go sleep now ​​​​​ ​​​​...  non-suicide\n",
       "99974       Day 64 of posting lines from the Bee Movie eve...  non-suicide\n",
       "219671      Shit I forgot to give reddit my email, and ive...  non-suicide\n",
       "297484      I blew up at my abusive parents after they cal...  non-suicide\n",
       "342310      I wish I had a girlfriend But I don’t have any...  non-suicide\n",
       "273746      Every since my dad passed I want to join him.L...      suicide\n",
       "74693       I feel stuckIdk if I want to feel better. Ther...      suicide\n",
       "96111       short advice from a boy, about boys Boys are p...  non-suicide\n",
       "181811      I have a question I can't upload images on r/t...  non-suicide\n",
       "100617      Today Will Be My Last Day Alive!!Incoming Long...      suicide\n",
       "286565      This is how people make me feel How I feel whe...  non-suicide\n",
       "140727      Im lonely as heccc any quirky cuties wanna dm?...  non-suicide\n",
       "328153      Try solve this numerical series 3; 5; 4; 9; 6;...  non-suicide\n",
       "277381      Eternal Oblivion is Calling my Name. . .The la...      suicide\n",
       "113347      Just kinda want to talk.I havent been in a gre...      suicide"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_suicide.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "id": "7u8UJyqXI5Uv",
    "outputId": "36c7c4d8-6cf3-4f3d-f388-67e3482f751a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>195700</td>\n",
       "      <td>195700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>195700</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>i want to destroy myselffor once everything wa...</td>\n",
       "      <td>non-suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>110165</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text        class\n",
       "count                                              195700       195700\n",
       "unique                                             195700            2\n",
       "top     i want to destroy myselffor once everything wa...  non-suicide\n",
       "freq                                                    1       110165"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Información del DataFrame\n",
    "df_suicide.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6AW4rEa_Oxc4",
    "outputId": "4053747b-bf28-4713-d6fd-720269e29670"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 195700 entries, 173271 to 305170\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text    195700 non-null  object\n",
      " 1   class   195700 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 4.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df_suicide.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Zj74SqmJitR"
   },
   "source": [
    "# 2. Preprocesamiento y preparación de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QIJ4S79aBmht"
   },
   "source": [
    "Vamos a definir diferentes funciones para que puedan ser condensadas en transformadores que luego serán interpretados por el Pipeline.\n",
    "El código se encuentra comentado dado que tuvimos que realizar estas clases en un archivo a parte para que el joblib que contiene el modelo pudiese cargarse de manera apropiada en la aplicación. Este archivo en cuestión se llama \"cleaners.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 394
    },
    "id": "_d5qOOmIJse3",
    "outputId": "5c2a094c-9bc2-46d8-8a02-56c22e7e8aae"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>173271</th>\n",
       "      <td>i want to destroy myselffor once everything wa...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336321</th>\n",
       "      <td>I kinda got behind schedule with learning for ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256637</th>\n",
       "      <td>I'm just not sure anymoreFirst and foremost: I...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303772</th>\n",
       "      <td>please give me a reason to liveThats too much ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293747</th>\n",
       "      <td>27f struggling to find meaning moving forwardI...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205651</th>\n",
       "      <td>Let’s get this bread 😎 Anyone know any good ba...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97174</th>\n",
       "      <td>Day 126 of posting random \"fun\" facts everyday...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195945</th>\n",
       "      <td>Little brother is self mutilating. Please help...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305273</th>\n",
       "      <td>Why do women always go in groups to their wash...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69929</th>\n",
       "      <td>Did you guys know that there's no school for g...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         text  class\n",
       "Unnamed: 0                                                          \n",
       "173271      i want to destroy myselffor once everything wa...      1\n",
       "336321      I kinda got behind schedule with learning for ...      0\n",
       "256637      I'm just not sure anymoreFirst and foremost: I...      1\n",
       "303772      please give me a reason to liveThats too much ...      1\n",
       "293747      27f struggling to find meaning moving forwardI...      1\n",
       "205651      Let’s get this bread 😎 Anyone know any good ba...      0\n",
       "97174       Day 126 of posting random \"fun\" facts everyday...      0\n",
       "195945      Little brother is self mutilating. Please help...      1\n",
       "305273      Why do women always go in groups to their wash...      0\n",
       "69929       Did you guys know that there's no school for g...      0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Conversión a numérico de la etiqueta\n",
    "def class_sui(text):\n",
    "  if text == 'suicide':\n",
    "    return 1\n",
    "  else:\n",
    "    return 0\n",
    "\n",
    "df_suicide['class'] = df_suicide['class'].apply(class_sui)\n",
    "\n",
    "\"\"\"#Pasamos a minuscula\n",
    "def minuscula(text):\n",
    "  texto =[]\n",
    "  for word in text:\n",
    "    textos= word.lower()\n",
    "    texto.append(textos)\n",
    "  listToStr = ''.join([str(elem) for elem in texto]) \n",
    "  return listToStr  \n",
    "\n",
    "#Eliminamos los números\n",
    "def numeros(text):\n",
    "  x=inflect.engine()\n",
    "  texto = []\n",
    "  for word in text :\n",
    "      word.replace(\" \",\"\")\n",
    "      if word.isdigit():\n",
    "         textos=x.number_to_words(word)\n",
    "         texto.append(textos)\n",
    "      else:\n",
    "         texto.append(word)    \n",
    "  return texto   \n",
    "\n",
    "def preprocesamiento(text):\n",
    "  texto = minuscula(text)\n",
    "  #texto = numeros(texto)\n",
    "  return texto\n",
    "\"\"\"\n",
    "df_suicide.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nv1WMur-Kqk1"
   },
   "source": [
    "Definimos las funciones para la tokenización y limpieza de datos final.\n",
    "El código se encuentra comentado dado que tuvimos que realizar estas clases en un archivo a parte para que el joblib que contiene el modelo pudiese cargarse de manera apropiada en la aplicación. Este archivo en cuestión se llama \"cleaners.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "U0c6aYfKJiA8"
   },
   "outputs": [],
   "source": [
    "\"\"\"def limpieza_tokens(df):\n",
    "  tokenizer = RegexpTokenizer(r'\\w+')\n",
    "  lemmatizer = WordNetLemmatizer()\n",
    "  list_token = []\n",
    "  for text in df['text']:\n",
    "      # tokenize it \n",
    "      result = []\n",
    "      results = tokenizer.tokenize(text)\n",
    "      for word in results:\n",
    "          # lemmatize it \n",
    "          words = lemmatizer.lemmatize(word)\n",
    "          result.append(words)\n",
    "      list_token.append(result)\n",
    "\n",
    "  #Lista de stopwords\n",
    "  count_vec = CountVectorizer(input='content', stop_words='english')\n",
    "  stopw = set(count_vec.get_stop_words())\n",
    "\n",
    "  #Eliminamos artículos, conjunciones, preposiciones, etc\n",
    "\n",
    "  for a in range(0,len(list_token)-1):\n",
    "    borrables = []\n",
    "    for b in range(0,len(list_token[a])-1):\n",
    "      if list_token[a][b] == 'm' or list_token[a][b] == 's' or list_token[a][b] == 've' or list_token[a][b] == 'don' or list_token[a][b] == 't' or list_token[a][b] == 'd' or list_token[a][b] == 'll' or list_token[a][b] in stopw:\n",
    "        borrables.append(list_token[a][b])\n",
    "    for c in borrables:\n",
    "      list_token[a].remove(c)\n",
    "\n",
    "  lst = []\n",
    "  for i in list_token:\n",
    "      listToStr = ' '.join([str(elem) for elem in i]) \n",
    "      lst.append(listToStr)\n",
    "  return lst\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aHcVe8wjMtb1"
   },
   "source": [
    "Ahora creamos las clases que nos servirán para que el Pipeline transforme los datos apropiadamente.\n",
    "El código se encuentra comentado dado que tuvimos que realizar estas clases en un archivo a parte para que el joblib que contiene el modelo pudiese cargarse de manera apropiada en la aplicación. Este archivo en cuestión se llama \"cleaners.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "SDpBJ6uKMsaV"
   },
   "outputs": [],
   "source": [
    "\"\"\"#Clase de la transformación del texto\n",
    "class Texto_Basico(BaseEstimator,TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self,X,y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self,X,y=None):\n",
    "        X = pd.DataFrame(X).copy()\n",
    "        X['text'] = X['text'].apply(preprocesamiento)\n",
    "        return X\"\"\"\n",
    "from cleaners import Texto_Basico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "AvdEXFqvPkfv"
   },
   "outputs": [],
   "source": [
    "\"\"\"#Clase de la tokenización y retoques finales\n",
    "class Texto_Definitivo(BaseEstimator,TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self,X,y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self,X,y=None):\n",
    "        print(X.head(10))\n",
    "        X = pd.DataFrame(X).copy()\n",
    "        X['text'] = limpieza_tokens(X)\n",
    "        print(X.info())\n",
    "        return X\n",
    "\"\"\"\n",
    "from cleaners import Texto_Definitivo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vaSujvCPYoOG"
   },
   "source": [
    "# 3. Creación del Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "RlGR5MN6Qci8"
   },
   "outputs": [],
   "source": [
    "#Pasos que ha de seguir el pipeline\n",
    "transformer = ColumnTransformer(\n",
    "    [('vec', TfidfVectorizer(), 'text')],   # column should be a string or int\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "pre = [('texto', Texto_Basico()),\n",
    "      ('token_y_mas', Texto_Definitivo()),\n",
    "      ('tfidf_vectorizer', transformer),\n",
    "      ('model', naive_bayes.MultinomialNB())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jcEjdyyCTvZu",
    "outputId": "4c05bdc8-c606-4472-be55-1363de289cb5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                         text\n",
      "Unnamed: 0                                                   \n",
      "173271      i want to destroy myselffor once everything wa...\n",
      "336321      i kinda got behind schedule with learning for ...\n",
      "256637      i'm just not sure anymorefirst and foremost: i...\n",
      "303772      please give me a reason to livethats too much ...\n",
      "293747      27f struggling to find meaning moving forwardi...\n",
      "205651      let’s get this bread 😎 anyone know any good ba...\n",
      "97174       day 126 of posting random \"fun\" facts everyday...\n",
      "195945      little brother is self mutilating. please help...\n",
      "305273      why do women always go in groups to their wash...\n",
      "69929       did you guys know that there's no school for g...\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 195700 entries, 173271 to 305170\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text    195700 non-null  object\n",
      "dtypes: object(1)\n",
      "memory usage: 3.0+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Se ajusta el pipeline a los datos\n",
    "X = df_suicide.drop('class',axis=1)\n",
    "y = df_suicide['class']\n",
    "\n",
    "pipeline = Pipeline(pre)\n",
    "pipeline = pipeline.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                         text\n",
      "Unnamed: 0                                                   \n",
      "173271      i want to destroy myselffor once everything wa...\n",
      "336321      i kinda got behind schedule with learning for ...\n",
      "256637      i'm just not sure anymorefirst and foremost: i...\n",
      "303772      please give me a reason to livethats too much ...\n",
      "293747      27f struggling to find meaning moving forwardi...\n",
      "205651      let’s get this bread 😎 anyone know any good ba...\n",
      "97174       day 126 of posting random \"fun\" facts everyday...\n",
      "195945      little brother is self mutilating. please help...\n",
      "305273      why do women always go in groups to their wash...\n",
      "69929       did you guys know that there's no school for g...\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 195700 entries, 173271 to 305170\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text    195700 non-null  object\n",
      "dtypes: object(1)\n",
      "memory usage: 3.0+ MB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9154215636177824"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.score(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "eXG5zzzRukWG"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Proyecto1-Parte2Pro.joblib']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Usamos la libreria joblib\n",
    "filename = 'Proyecto1-Parte2Pro.joblib'\n",
    "\n",
    "dump(pipeline, filename)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
